{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import re\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "subreddit = \"depression\"\n",
    "# posts\n",
    "dataPostsAll = pd.read_json(subreddit+'_posts_2017.txt')\n",
    "\n",
    "# comentários\n",
    "dataCommentsAll = pd.read_json(subreddit+'_comments_2017.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataComments = dataCommentsAll[['id','author','body', 'link_id', 'parent_id', 'subreddit']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataPosts = dataPostsAll[['id','author', 'num_comments', 'score', 'selftext','subreddit']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### POSTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# remover os posts removidos\n",
    "dataPosts = dataPosts[dataPosts.selftext != '[removed]']\n",
    "# remover os posts deletados\n",
    "dataPosts = dataPosts[dataPosts.selftext != '[deleted]']\n",
    "\n",
    "# remover os posts dos autores removidos\n",
    "dataPosts = dataPosts[dataPosts.author != '[removed]']\n",
    "# remover os posts dos autores  deletados\n",
    "dataPosts = dataPosts[dataPosts.author != '[deleted]']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tirar o \"\\n\" do texto selftext e body\n",
    "dataPosts['selftext'].replace(regex=True,inplace=True,to_replace=r'\\n',value=r'')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# remover os comentarios removidos\n",
    "dataComments = dataComments[dataComments.body != '[removed]']\n",
    "# remover os comentrios deletados\n",
    "dataComments = dataComments[dataComments.body != '[deleted]']\n",
    "\n",
    "# remover os coments dos autores removidos\n",
    "dataComments = dataComments[dataComments.author != '[removed]']\n",
    "# remover os comments dos autores  deletados\n",
    "dataComments = dataComments[dataComments.author != '[deleted]']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataComments['body'].replace(regex=True,inplace=True,to_replace=r'\\n',value=r'')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataComments['link_id'].replace(regex=True,inplace=True,to_replace='t3_',value='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataComments[\"type\"] = \"comments\"\n",
    "dataPosts[\"type\"] = \"posts\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove stopwords \"body\" and \"selfText\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Barbara\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stop_words = list(stopwords.words('english')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stop_words.append(\"im\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\",\n",
       " 'im']"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# remove pontuação\n",
    "dataComments[\"body\"] = dataComments[\"body\"].str.replace('[^\\w\\s]',' ')\n",
    "dataPosts[\"selftext\"] = dataPosts[\"selftext\"].str.replace('[^\\w\\s]',' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#remover stopwords\n",
    "dataComments['body_semStopWords'] = dataComments['body'].apply(lambda x: ' '.join([word for word in x.split() if word.lower() not in (stop_words)]))\n",
    "dataPosts[\"selftext_semStopWords\"] = dataPosts[\"selftext\"].apply(lambda x: ' '.join([word for word in x.split() if word.lower() not in (stop_words)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# remover execesso de espaços\n",
    "dataComments['body_semStopWords'] = dataComments['body_semStopWords'].str.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Eliminar palavras que deram problema no RMN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Barbara\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\Barbara\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
      "  import sys\n",
      "C:\\Users\\Barbara\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#NAN\n",
    "dataComments[\"body_semStopWords\"] = dataComments[\"body_semStopWords\"].str.lower().str.replace(r\"(\\snan\\s)|(^nan\\s)|(\\snan$)|(^nan$)\", ' ')\n",
    "len(dataComments[dataComments[\"body_semStopWords\"].str.lower().str.contains(r\"(\\snan\\s)|(^nan\\s)|(\\snan$)|(^nan$)\")])\n",
    "\n",
    "#NA\n",
    "dataComments[\"body_semStopWords\"] = dataComments[\"body_semStopWords\"].str.lower().str.replace(r\"(\\sna\\s)|(^na\\s)|(\\sna$)|(^na$)\", ' ')\n",
    "len(dataComments[dataComments[\"body_semStopWords\"].str.lower().str.contains(r\"(\\sna\\s)|(^na\\s)|(\\sna$)|(^na$)\")])\n",
    "\n",
    "#null\n",
    "dataComments[\"body_semStopWords\"] = dataComments[\"body_semStopWords\"].str.lower().str.replace(r\"(\\snull\\s)|(^null\\s)|(\\snull$)|(^null$)\", ' ')\n",
    "len(dataComments[dataComments[\"body_semStopWords\"].str.lower().str.contains(r\"(\\snull\\s)|(^null\\s)|(\\snull$)|(^null$)\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataComments.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Barbara\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\Barbara\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
      "  import sys\n",
      "C:\\Users\\Barbara\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#NAN\n",
    "dataPosts[\"selftext_semStopWords\"] = dataPosts[\"selftext_semStopWords\"].str.lower().str.replace(r\"(\\snan\\s)|(^nan\\s)|(\\snan$)|(^nan$)\", ' ')\n",
    "len(dataPosts[dataPosts[\"selftext_semStopWords\"].str.lower().str.contains(r\"(\\snan\\s)|(^nan\\s)|(\\snan$)|(^nan$)\")])\n",
    "\n",
    "#NA\n",
    "dataPosts[\"selftext_semStopWords\"] = dataPosts[\"selftext_semStopWords\"].str.lower().str.replace(r\"(\\sna\\s)|(^na\\s)|(\\sna$)|(^na$)\", ' ')\n",
    "len(dataPosts[dataPosts[\"selftext_semStopWords\"].str.lower().str.contains(r\"(\\sna\\s)|(^na\\s)|(\\sna$)|(^na$)\")])\n",
    "\n",
    "#Null\n",
    "dataPosts[\"selftext_semStopWords\"]= dataPosts[\"selftext_semStopWords\"].str.lower().str.replace(r\"(\\snull\\s)|(^null\\s)|(\\snull$)|(^null$)\", ' ')\n",
    "len(dataPosts[dataPosts[\"selftext_semStopWords\"].str.lower().str.contains(r\"(\\snull\\s)|(^null\\s)|(\\snull$)|(^null$)\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataPosts.isnull().values.any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tirar textos != de ingles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# não achei nenhum algorimo bom e acredito q não vai fazer muito diferença para os descritores, uma vez que os textos são a maioria"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remover acentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import unicodedata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# remover do comentarios\n",
    "dataComments[\"body_semStopWords\"] = dataComments[\"body_semStopWords\"].str.normalize('NFKD').str.encode('ascii', errors='ignore').str.decode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# remover dos posts\n",
    "dataPosts[\"selftext_semStopWords\"] = dataPosts[\"selftext_semStopWords\"].str.normalize('NFKD').str.encode('ascii', errors='ignore').str.decode('utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Posts e Comentários por usuário "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:red\"> Acredito que isso não é necessário</span>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# autores únicos das postagens\n",
    "#authorPosts = dataPosts.author.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# autores únicos dos comentarios\n",
    "#authorComments = dataComments.author.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#authorsIntesec = set.intersection(set(authorPosts),set(authorComments))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#for a in authorsIntesec:\n",
    "    #dataPosts[(dataPosts.author == a)].to_csv(\"depression_2017.txt\", \";\", columns=headerPost, mode='a', header=False)\n",
    "    #dataComments[(dataComments.author == a)].to_csv(\"depression_2017.txt\", \";\", columns=headerCom, mode='a', header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gerar Arquivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# remover linhas vazias\n",
    "dataPosts = dataPosts.drop(dataPosts[(dataPosts.selftext_semStopWords.str.strip() == '')].index)\n",
    "dataComments = dataComments.drop(dataComments[(dataComments.body_semStopWords.str.strip() == '')].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nameFile = subreddit + \"_2017.txt\"\n",
    "file = open(nameFile,\"w\") \n",
    "file.write(\"subs;user;spans;masks\")\n",
    "file.write(\"\\n\")\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "headerPost = ['subreddit', 'author','selftext_semStopWords','type']\n",
    "headerCom =  ['subreddit', 'author', 'body_semStopWords','type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataPosts.to_csv(nameFile, \";\", columns=headerPost, mode='a', header=False, index=False)\n",
    "dataComments.to_csv(nameFile, \";\", columns=headerCom, mode='a', header=False, index=False)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "526322"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataComments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "89394"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataPosts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#fileSpans = \"spans_2017\"\n",
    "#file = open(fileSpans,\"w\") \n",
    "#dataPosts.to_csv(fileSpans, \"\\n\", columns=[\"selftext_semStopWords\"], mode='a', header=False, index=False)\n",
    "#dataComments.to_csv(fileSpans , \"\\n\", columns=[\"body_semStopWords\"], mode='a', header=False, index=False)\n",
    "#file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### métricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>author</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>score</th>\n",
       "      <th>selftext</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>type</th>\n",
       "      <th>selftext_semStopWords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7gqwf4</td>\n",
       "      <td>heresmythrowaway3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>I know the post is vague  I ve just been feeli...</td>\n",
       "      <td>depression</td>\n",
       "      <td>posts</td>\n",
       "      <td>know post vague feeling lot emotional pain las...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7gqwwy</td>\n",
       "      <td>vaan0011</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>I was born with an Imperforate Anus  which mea...</td>\n",
       "      <td>depression</td>\n",
       "      <td>posts</td>\n",
       "      <td>born imperforate anus mean anus born parent so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7gqxyo</td>\n",
       "      <td>_NoIdea_</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>Hello everyone  first time posting here and it...</td>\n",
       "      <td>depression</td>\n",
       "      <td>posts</td>\n",
       "      <td>hello everyone first time posting new account ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7gqy42</td>\n",
       "      <td>Yteburk</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>I feel like I ve wasted so much potential  I m...</td>\n",
       "      <td>depression</td>\n",
       "      <td>posts</td>\n",
       "      <td>feel like wasted much potential pretty sure al...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7gr1p3</td>\n",
       "      <td>_mbh_</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Just spent that day with the girl I ve been li...</td>\n",
       "      <td>depression</td>\n",
       "      <td>posts</td>\n",
       "      <td>spent day girl liking great funny smart feisty...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id             author  num_comments  score  \\\n",
       "0  7gqwf4  heresmythrowaway3             1      1   \n",
       "2  7gqwwy           vaan0011             0      2   \n",
       "3  7gqxyo           _NoIdea_             9      2   \n",
       "4  7gqy42            Yteburk             0      1   \n",
       "8  7gr1p3              _mbh_             1      1   \n",
       "\n",
       "                                            selftext   subreddit   type  \\\n",
       "0  I know the post is vague  I ve just been feeli...  depression  posts   \n",
       "2  I was born with an Imperforate Anus  which mea...  depression  posts   \n",
       "3  Hello everyone  first time posting here and it...  depression  posts   \n",
       "4  I feel like I ve wasted so much potential  I m...  depression  posts   \n",
       "8  Just spent that day with the girl I ve been li...  depression  posts   \n",
       "\n",
       "                               selftext_semStopWords  \n",
       "0  know post vague feeling lot emotional pain las...  \n",
       "2  born imperforate anus mean anus born parent so...  \n",
       "3  hello everyone first time posting new account ...  \n",
       "4  feel like wasted much potential pretty sure al...  \n",
       "8  spent day girl liking great funny smart feisty...  "
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataPosts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dicioComments = dict(dataComments.groupby(\"author\")['body_semStopWords'].count())\n",
    "dicioPosts  = dict(dataPosts.groupby(\"author\")['selftext_semStopWords'].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Qtde Comments >= 50 =  1416\n"
     ]
    }
   ],
   "source": [
    "# comentarios\n",
    "contComment = 0\n",
    "for item in sorted(dicioComments, key = dicioComments.get,  reverse=True):\n",
    "    #print (dicioComments[item])\n",
    "    if(dicioComments[item] >= 50):\n",
    "        contComment = contComment + 1\n",
    "print(\"Qtde Comments >= 50 = \", contComment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Qtde Posts >= 50 =  27\n"
     ]
    }
   ],
   "source": [
    "# posts\n",
    "contPosts = 0\n",
    "for item in sorted(dicioPosts, key = dicioPosts.get):\n",
    "    #print (dicioPosts[item])\n",
    "    if(dicioPosts[item] >= 50):\n",
    "        contPosts = contPosts + 1\n",
    "print(\"Qtde Posts >= 50 = \", contPosts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# funciona, só nao faz filter ainda..\n",
    "# commentsGroup = dataComments.groupby(\"author\")['body_semStopWords'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# postsGroup = dataPosts.groupby(\"author\")['selftext_semStopWords'].count()\n",
    "#postsGroup = dataPosts.groupby(\"author\")['selftext_semStopWords'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
